# Resumen Inteligencia de Negocio

- [4. Predicci칩n: clasificaci칩n](#4-predicci칩n-clasificaci칩n)
  - [Generalidades](#generalidades)
  - [Algunos clasificadores sencillitos](#algunos-clasificadores-sencillitos)
    - [ZeroR](#zeror)
    - [OneR](#oner)
    - [K-Nearest Neighbours](#k-nearest-neighbours)
  - [Evaluaci칩n de clasificadores](#evaluaci칩n-de-clasificadores)
  - [츼rboles y reglas de asociaci칩n](#치rboles-y-reglas-de-asociaci칩n)
  - [Clasificadores basados en reglas](#clasificadores-basados-en-reglas)
  - [Clasificadores basados en m칠todos bayesianos](#clasificadores-basados-en-m칠todos-bayesianos)
  - [Clasificadores basados en instancias](#clasificadores-basados-en-instancias)
  - [Clasificadores basados en redes neuronales](#clasificadores-basados-en-redes-neuronales)
  - [Clasificadores basados en m치quinas de soporte vectorial](#clasificadores-basados-en-m치quinas-de-soporte-vectorial)
  - [Multiclasificadores](#multiclasificadores)
- [5. Preprocesamiento de datos](#5-preprocesamiento-de-datos)
  - [Introducci칩n](#introducci칩n)
  - [Integraci칩n, limpieza y transformaci칩n](#integraci칩n-limpieza-y-transformaci칩n)
  - [Datos imperfectos](#datos-imperfectos)
  - [Reducci칩n de datos](#reducci칩n-de-datos)
- [Tema 6: Clustering](#tema-6-clustering)
  - [K-Means](#k-means)
  - [Mean Shift](#mean-shift)
  - [DBSCAN](#dbscan)
  - [BIRCH](#birch)
  - [Medidas](#medidas)
  - [M칠todos aglomerativos](#m칠todos-aglomerativos)
  - [M칠todos divisivos](#m칠todos-divisivos)
- [Tema 7: Patrones frecuentes y reglas de asociaci칩n](#tema-7-patrones-frecuentes-y-reglas-de-asociaci칩n)
  - [Algoritmo APRIORI](#algoritmo-apriori)
  - [Medidas de inter칠s](#medidas-de-inter칠s)
- [Tema 8: Deep Learning](#tema-8-deep-learning)
  - [La nueva forma de entrenar RNA multicapa: aprendizaje profundo](#la-nueva-forma-de-entrenar-rna-multicapa-aprendizaje-profundo)
  - [CNN: Convolucional Neural Network](#cnn-convolucional-neural-network)
- [Tema 9: Problemas regulares](#tema-9-problemas-regulares)
- [9. Problemas singulares](#9-problemas-singulares)

## 4. Predicci칩n: clasificaci칩n

### Generalidades

Tipos de variables habituales:
- Num칠rica (ordinal)
- Categ칩rica o nominal (no hay orden)

Tipos de aprendizaje autom치tico:
|                | **Supervisado** |  **No supervisado**  |
|:---------------|:---------------:|:--------------------:|
| **Categ칩rico** |  Clasificaci칩n  | Reglas de asociaci칩n |
| **Continuo**   |    Regresi칩n    |      Clustering      |

Etapas del proceso de clasificaci칩n:
Ejemplos de entrenamiento -> sistema de clasificaci칩n -> ejemplos de prueba. Extraer estad칤sticas sobre el modelo en estos ejemplos de prueba.

Matriz de confusi칩n:
| Predicho \ Real | **Positivo** | **Negativo** |
|:----------------|:------------:|:------------:|
| **Positivo**    |      VP      |      FN      |
| **Negativo**    |      FP      |      VN      |

- Acierto = $\frac{VP + VN}{VP + VN + FP + FN}$; precisi칩n o exactitud.
- Error = $1 - acierto$
- Velocidad: tiempo necesario para la construcci칩n y el uso del modelo.
- Robustez: capacidad para tratar con valores desconocidos.
- Escalabilidad: aumento del tiempo necesario con el tama침o de la base datos.
- Interpretabilidad: comprensibilidad del modelo obtenido.
- Complejidad del modelo: tama침o del 치rbol, n칰mero de reglas...

### Algunos clasificadores sencillitos

#### ZeroR
- Todas las instancias se clasifican en la clase mayoritaria.

#### OneR

- Clasificador formado por reglas con una 칰nica variable en el antecedente.
- Reglas del tipo `si variable == valor => clase = categor칤a`

#### K-Nearest Neighbours
- Almacenas una tabla con los ejemplos disponibles, junto a la clase asociada a cada uno de ellos
- Cuando quieras clasificar un ejemplo, seleccionas los k vecinos m치s cercanos a 칠l, y se clasifica como la clase que m치s aparece entre esos vecinos.


### Evaluaci칩n de clasificadores

- El objetivo es hacer una estimaci칩n honesta del modelo generado.
- Utilizar como bondad la tasa de acierto sobre el set de entrenamiento no te vale para nada. Suele ser demasiado optimista.
- T칠cnicas de evaluaci칩n:
  - **Hold-out**:
    - Divides la base de datos en set de entrenamiento y set de pruebas.
    - Elementos del training obtenidos normalmente por muestreo sin reemplazamiento. Los del test son aquellos que no han aparecido en el del training.
    - Usado en bases de datos grandes
  - **Validaci칩n cruzada** (Cross-validation):
    - Divides la base de datos en $k$ subconjuntos $\text{Folds} = \{S_1, ..., S_k\}$.
    - Sacas $k$ clasificadores, utilizando como set de entrenamiento $\text{Folds} - S_i$, y como test $S_i$.
    - Devuelves como tasa de acierto el promedio obtenido en las $k$ iteraciones.
    - Se suele usar en bases de datos de tama침o moderado.
  - **Leaving one out**:
    - Cross validation pero $k = \text{n칰mero de registros}$. Es decir, utilizas todas las instancias menos una. Y testeas sobre esa.
    - Tardas un huevo y medio en ejecutarlo, as칤 que te vale solo para bases de datos chiquitillas.
  - **Bootstrap**:
    - Basado en muestreo con reposici칩n. A partir de una base de datos de tama침o $n$, seleccionas $n$ instancias al azar, y se utilizan como set de entrenamiento. Como es con reposici칩n, la probabilidad de que no se seleccione un ejemplo es $(1 - \frac{1}{n})^n \rightarrow e^{-1} \approx 0.368$.
    - Para calcular el error sobre el set de test, corriges el error para no ser tan pesimista. Te sale $\text{error} = 0.632 \cdot error_{test} + 0.368 \cdot error_{training}$

### 츼rboles y reglas de asociaci칩n

- Clasificador que en funci칩n de un conjunto de atributos permite determinar a qu칠 clase pertenece el objeto de estudio.
- **Estructura**:
  - Nodo: una prueba realizada sobre los atributos
  - Hojas: clase de la variable objeto de la clasificaci칩n.
- **Construcci칩n**:
   1. Al principio, todos los ejemplos de entrenamiento est치n en el nodo ra칤z.
   2. Se van dividiendo recursivamente en base a los atributos seleccionados.
      - Si los atributos son categ칩ricos, hace falta discretizarlos.
      - Se seleccionan en base a una heur칤stica.
   3. Se poda el 치rbol para quitar ramas que describen ruido o datos an칩malos.
   4. Condiciones para terminar:
      - Todos los ejemplos pertenecen a la misma clase.
      - No quedan m치s atributos para seguir particionando => utilizar el voto de la mayor칤a.
      - No quedan ejemplos.
- 쮺칩mo seleccionar cu치l es el **mejor atributo**?
  - Primero, definimos la entrop칤a de una variable, porque no somos unos psic칩patas como el que hizo los apuntes:
    - La entrop칤a de una variable X, $H(X) = -\sum_{i}{p(x_i) \cdot log_{2}(p(x_i))}$. Adem치s, consideramos $X^{*}$ el atributo a seleccionar.
    - **La entrop칤a mide la aleatoriedad, sorpresa o incertidumbre al predecir una cierta clase**.
  - Probablemente este tocho de f칩rmulas no sirva para nada, as칤 que puedes ignorarlo dentro de lo razonable. Eso s칤, apr칠ndete los nombres y la idea detr치s de cada medida.
  - La ganancia de informaci칩n, **InfoGain**, viene dado por $X^{*} = \max_{X}{H(C) - H(C \vert X)}$. Es usado por ID3.
    - Suponiendo que hay dos clases, $P$, $N$, que tienen $p$, $n$ elementos cada una en el set considerado, entonces, la cantidad de informaci칩n necesaria para decidir si un ejemplo pertenece a $P$ o $N$ viene dado por la siguiente expresi칩n: $H(C) = H(p, n) = - \frac{p}{p + n} \cdot log_2(\frac{p}{p + n}) - \frac{n}{p + n} \cdot log_2(\frac{n}{p + n})$.
    - Consideremos que, utilizando un atributo $A$, el conjunto se puede dividir en $v$ conjuntos diferentes. Si ahora hay $p_i$ de la clase $P$, y $n_i$ de la clase $N$, entonces $H(C \vert A) = \sum_{i = 1}^{v}{\frac{p_i + n_i}{p+n}H(p_i, n_i)}$.
    - La informaci칩n que se podr칤a ganar con una rama que considere $A$ es $Gain(A) = H(p, n) - H(C \vert A)$.
  - Modificando un poco lo anterior para tener en cuenta el ratio, obtenemos **GainRatio**, definido como $X^{*} = \max_{X}{\frac{H(C) - H(C \vert X)}{H(X)}}$. Lo introdujo C4.5 (*que no es el hermano del creador de la m칰sica de Minecraft*).
  - Por 칰ltimo, CART us칩 el **칤ndice Gini**. Sabiendo que $G = 1 - \sum_{i = 1}^{n}{p_i^2}$, (donde $p_i$ es la frecuencia relativa de la clase $i$ en el conjunto de datos), entonces $X^{*} = \max_{X}{G(C) - G(C \vert X)}$.
    - Si se divide el conjunto de datos en $T_1$, $T_2$ de tama침os $N_1$, $N_2$, entonces $gini_split(T) = \frac{N_1}{N}gini(T1) + \frac{N_2}{N}gini(T_2)$.
- **Ventajas e inconvenientes** de los 치rboles de decisi칩n:
  - **Ventajas**:
    - F치ciles de utilizar y eficientes
    - Generan reglas que son f치ciles de interpretrar
    - Escalan mejor que otro tipo de t칠cnicas
    - Tratan bien los datos con ruido
  - **Inconvenientes**:
    - No manejan bien los atributos continuos
    - Tratan de dividir el dominio de los atributos en regiones rectangulares. No todos los problemas son de ese tipo.
    - Tienen dificultad para trabajar con valores perdidos.
    - Pueden tener problemas de sobreaprendizaje.
    - No detectan correlaciones entre atributos.
- **Algoritmos basados en 치rboles de decisi칩n**:
  - **ID3**:
    - Utiliza conceptos de teor칤a de la informaci칩n
    - Reduce el n칰mero de comparaciones
    - Utiliza la ganancia de la informaci칩n (**InfoGain**). En cada paso, intenta maximizarla.
    - El espacio de hip칩tesis es completo; la funci칩n objetivo est치 incluida en 칠l.
    - No es capaz de determinar todos los 치rboles compatibles con los ejemplos de entrenamiento, ni puede proponer ejemplos que reduzcan el espacio de b칰squeda.
    - No hay vuelta atr치s => **se queda estancado en 칩ptimos locales**.
    - **Permite ruido** en los ejemplos de entrenamiento.
    - **Por la ganancia de informaci칩n, tiene tendencia a elegir atributos con muchos valores**.
    - **Se prefieren 치rboles cortos** frente a largos, con los atributos que producen mayor ganancia cerca de la ra칤z.
    - **Refinamientos posibles** (*aka problemas que tiene*):
      - Cu치ndo parar en la construcci칩n del 치rbol
      - Atributos continuos
      - Ejemplos incompletos
  - **C4.5**:
    - Mejora a ID3 en los siguientes aspectos:
      - **Datos perdidos**: se ignoran en la construcci칩n del 치rbol. Para clasificar uno con valores perdidos, se predice en base a los otros atributos del registro.
      - **Datos continuos**: Se divide en rangos en base a los valores que toma en el conjunto de entrenamiento.
      - **Soluciones para el sobreaprendizaje**:
        - Prepoda: se decide cu치ndo dejar de subdividir el 치rbol. No se divide un nodo cuando se tiene poca confianza en 칠l
        - Postpoda: se construye el 치rbol y despu칠s se poda. Estrategias:
          - Reemplazamiento de sub치rboles; se reemplaza un sub치rbol por una hoja si al hacerlo el error es similar al original
          - Elevaci칩n de sub치rboles: reemplaza un sub치rbol por otro si se utiliza m치s.
    - Permite generar reglas a partir del 치rbol.
    - Selecci칩n de atributos: **se utiliza GainRatio**.
    - No maneja bien clases desbalanceadas

### Clasificadores basados en reglas

- Una regla est치 formada por:
  - Antecedente: contiene un predicado que se eval칰a como verdadero o falso
  - Consecuente: la clase que se predice.
- **Los 치rboles de decisi칩n y las reglas no son equivalentes**. Los 치rboles tienen orden impl칤cito. Las reglas no. El 치rbol se crea mirando todas las clases. Cuando se genera una regla, solo se examina la clase
- C칩mo generar reglas de decisi칩n:
  - Mediante **치rboles de decisi칩n**:
    - No se realiza un particionamiento exhaustivo del espacio de soluciones
  - Mediante **cobertura**:
    - Intentan generar reglas que cubran exactamente 1 clase.
    - Suelen generar la mejor regla posible optimizando la probabilidad de clasificaci칩n deseada.
    - Ejemplo: **OneR**
    - Ejemplo: **PRISM**. Genera reglas para cada clase mirando el conjunto de entrenamiento, y a침adiendo reglas que describan todos los ejemplos de dicha clase.
      - No garantiza obtener el conjunto 칩ptimo de reglas, al ser un greedy.
      - Sufre de sobreajuste.
      - Es un poco tru침o a d칤a de hoy.

### Clasificadores basados en m칠todos bayesianos

- Representan incertidumbre asociada a los procesos de forma natural.
- Utilizan el teorema de bayes de la probabilidad condicionada, y la hip칩tesis de *M치xima A Posteriori* (MAP).
- Ejemplo t칤pico: **Naive Bayes**
  - **Supone que todos los atributos son independientes conocida la variable clase**.
  - Simplifica la hip칩tesis MAP.
  - Consigue buenos resultados a pesar de esa suposici칩n.
  - Variables discretas => estimaci칩n por m치xima verosimilitud. Variables continuas => se asume una distribuci칩n normal.
- **Ventajas e inconvenientes**:
  - **Ventajas:**
    - F치cil de implementar
    - Buenos resultados en gran parte de los casos
  - **Inconvenientes:**
    - La suposici칩n de independencia supone una falta de precisi칩n. Casi siempre existe una cierta correlaci칩n. Para solucionarlo, se utilizan reyes de creencia bayesianas. Combinan razonamiento bayesiano con relaciones causales entre atributos.

### Clasificadores basados en instancias

- Basados en aprendizaje por analog칤a.
- **Paradigma perezoso**: no se construye modelo, sino que se utiliza la propia base de datos. Se trabaja cuando se llega un nuevo ejemplo a clasificar.
- Suelen estar basados en KNN.
  - Se suele normalizar.
  - Se suelen utilizar las distancias eucl칤deas, Manhattan y Minkowski
  - Para los missing values, se asigna la m치xima componente posible (i.e., si la normalizaci칩n es en $[0, 1]$ entonces le asignas $1$).
  - Para no considerar todas las variables igual de importantes, se pueden asignar pesos.
  - Matices:
    - Robusto frente a ruido (siempre que $k \gt 1$).
    - Eficaz, pues utiliza funciones lineales locales para aproximar la funci칩n objetivo.
    - V치lido para clasificaci칩n y predicci칩n num칠rica.
    - Ineficiente en memoria as fuck.
    - La distancia entre vecinos podr칤a estar dominada por variables irrelevantes
    - Complejidad de $O(\text{complejidad de la distancia} \cdot n^2)$

### Clasificadores basados en redes neuronales

- Ventajas y desventajas:
  - **Ventajas**:
    - Gran tasa de acierto en la predicci칩n
    - M치s robustas que los 치rboles de decisi칩n por los pesos
    - Robustez ante la presencia de errores (ruido, outliers...)
    - Gran capacidad de salida (nominal, num칠rica, vectorial...)
    - Eficiencia (== rapidez) en la evaluaci칩n de nuevos casos
    - Mejoran su rendimiento mediante aprendizaje y 칠ste puede continuar despu칠s de que se haya aplicado al conjunto de entrenamiento.
  - **Desventajas**:
    - Mucho tiempo de entrenamiento
    - Gran parte del entrenamiento es ensayo y error
    - Poca interpretabilidad del modelo. Se suele decir que es una caja negra (pero hoy en d칤a no es cierto esto).
    - Dif칤cil incorporar conocimiento del dominio.
    - Atributos de entrada deben ser num칠ricos
    - Generar reglas a partir del modelo no es inmediato
    - Pueden tener problemas de sobreaprendizaje.
- 쮺u치ndo utlizarlas?
  - La dimensi칩n de la entrada es alta
  - La salida es un valor discreto o vector de valores
  - Posibilidad de datos con ruido
  - La forma de la funci칩n objetiva es desconocida
  - La interpretabilidad de los datos no es importante
- Matices:
  - Todas las variables num칠ricas se normalizan en $[-1, 1]$
  - Algoritmo de backpropagation:
    - Basado en la t칠cnica del gradiente descendente
    - No permite conexiones hacia atr치s (retroalimentaci칩n) en la red
- Si quieres aprender en condiciones, te vas al canal de [DotCSV](https://www.youtube.com/watch?v=MRIv2IwFTPg&list=PL-Ogd76BhmcB9OjPucsnc2-piEE96jJDQ) y te pones a mirar sus v칤deos, que est치n much칤simo mejor que estos apuntes. Las redes neuronales cambian rapid칤simamente, y no merece la pena aprenderse este tipo de cosas as칤 como as칤. S칤, te estoy diciendo que ignores estos apuntes.


### Clasificadores basados en m치quinas de soporte vectorial

- Una SVM es un modelo de aprendizaje que se fundamente en la teor칤a de *aprendizaje estad칤stico*. La idea b치sica es encontrar un hiperplano can칩nico que maximice el margen del conjunto de datos de entrenamiento. Esto nos garantiza una buena capacidad de generaci칩n.
- Requiere que los datos sean linealmente separables.
- Explotan la informaci칩n que proporciona el producto escalar entre los datos disponibles.
- El problema es encontrar la funci칩n $\Phi$ que los separa. Por ello, se utilizan las funciones kernel, que es un producto interno de dos elementos en alg칰n espacio de caracter칤sticas inducido.
- Se utilizan los multiplicadores de Lagrange habitualmente.
- Fue dise침ado para resolver problemas de clasificaci칩n binaria. Para escalarlo a problemas multiclase, se realizan otras t칠cnicas que veremos en un segund칤n.

### Multiclasificadores

- La idea es inducir $n$ clasificadores en uno solo. Se utlizar치 una salida que es combinaci칩n de lo que proporciona cada uno.
- Pueden estar basados en diferentes t칠cnicas.
- Se pueden aplicar sobre el mismo clasificador o con diferentes.
- Formas de proporcionarse informaci칩n los unos a los otros:
  - **Bagging**, o bootstrap aggregating:
    - Cada clasificador se induce independientemente de los dem치s. Incluye una fase de diversificaci칩n sobre los datos.
    - Funciona bien para algoritmos de aprendizaje inestables; es decir, aquellos que con un peque침o cambio, producen resultados muy diferentes.
    - Ejemplo: **random forest**.
  - **Boosting**:
    - **Muestreo ponderado**: En lugar de hacer un muestreo aleatorio de los datos de entrenamiento, se ponderan las muestrar para concentrar el aprendizaje en los ejemplos m치s dif칤ciles. Los ejemplos m치s cercanos a la frontera son m치s dif칤ciles de clasificar, por lo que recibir치n un peso mayor.
    - **Votos ponderados**:
      - En lugar de combinar los clasificadores con el mismo peso en el voto, se utiliza un voto ponderado.
      - Esta es la regla de combinaci칩n para el conjunto de clasificadores d칠biles.
      - En conjunci칩n con la estrategia de muestro anterior, esto produce un clasificador m치s fuerte.
    - **Los modelos no se construyen independientemente**. La salida del clasificador $i$-칠simo afecta al $(i+1)$-칠simo. Se hace 칠nfasis en los que se han clasificado err칩neamente en los anteriores.
    - Ejemplo: adaptive boosting
    - [Una p치gina boniquilla para aprender las diferencias. Se entiende mejor as칤](https://quantdare.com/what-is-the-difference-between-bagging-and-boosting/)
- **Binarizaci칩n**:
  - Estrategia divide y vencer치s. Se descomponen los problemas en varios, y despu칠s se reconstruye todo.
  - Tipos:
    - **One on one** (OVO 游불) :
      - Uno pa uno sin camisa entre las posibles clases.
      - Se le llama pairwise learning, round robin...
      - Fase de agregaci칩n: se proponen diferentes v칤as para agrupar los clasificadores
    - **One for all** (OVA *como las de los animes*):
      - Venir a por m칤 con la cara destapad[a](https://www.youtube.com/watch?v=8hJ-okFUtT4): se enfrenta una clase ante el resto. Se separa 칠sta de todas las dem치s. Una vez por cada clase.
    - Ventajas:
      - Clasificadores m치s peque침os
      - Fronteras de decisi칩n m치s simples.


## 5. Preprocesamiento de datos

### Introducci칩n

- Preprocesamiento: tareas para disponer de datos de calidad previstos al uso de algoritmos de extracci칩n de conocimiento
- Importancia:
  - Los datos pueden ser impuros, lo que conducir칤a a modelos in칰tiles. Pueden estar incompletos, tener ruido, o ser inconsistentes.
  - El preprocesamiento puede generar conjuntos de datos m치s peque침os que el original, lo que mejora la eficiencia.
  - Genera datos de calidad. Ya' know, trash in, trash out. Luego veremos t칠cnicas que se usan para solucionarlo.
- Suele llevar la mayor parte del tiempo del proceso de ciencia de datos.
- La **preparaci칩n de datos** es el conjunto de t칠cnicas que inicializan los datos adecuadamente para que sirvan de entrada a los algoritmos. Compuesta por:
  - Limpieza
  - Normalizaci칩n
  - Transformaci칩n
  - Integraci칩n
  - Missing values imputation
  - Identificaci칩n de ruido
- La **reducci칩n de datos** son las t칠cnicas que se utilizan para simplificar los datasets. Incluye
  - Selecci칩n de caracter칤sticas
  - Selecci칩n de instancias
  - Discretizaci칩n
- Un orden sensato de preprocesamiento es
  1. Ruido
  2. Valores perdidos
  3. Selecci칩n de instancias

### Integraci칩n, limpieza y transformaci칩n
- **Integraci칩n de los datos**:
  - Obtiene los datos de diferentes fuentes de informaci칩n.
  - Resuelve problemas de representaci칩n y codificaci칩n
  - Integra los datos desde diferentes tablas para crear informaci칩n homog칠nea.
  - Cosas a tener en cuenta:
    - Hay que asegurar que las entidades se emparejan correctamente.
    - Detectar duplicados e inconsistencias
    - Cazar redundancia producida por las diferentes fuentes
    - Cuidado con los conflictos entre las bases de datos diferentes. Puede deberse a escalas diferentes, o incluso que no tengan sentido ninguno
  - El an치lasis de correlaciones resulta 칰til en este caso.
- **Limpieza**:
  - Objetivos:
    - Resolver inconsistencias
    - Rellenar/imputar valores perdidos == missing values
    - Suavizar el ruido
    - Identificar outliers y tratarlos.
  - Algunos algoritmos lo tienen incorporado. Pero ojito con fiarte.
- **Transformaci칩n**:
  - Aplicarle funciones para que se vuelvan m치s f치ciles de tratar. Ejemplos: quitar calles y poner c칩digos postales; agregar atributos, normalizar.
  - Tipos de normalizaci칩n:
    - min-max: normalizar a un intervalo determinado
    - Zero mean (aka Z-score): normalizar en funci칩n de la media y la desviaci칩n est치ndar. 칔til cuando tienes demasiados outliers.
    - Por escala decimal.

### Datos imperfectos

- **Valores perdidos** (aka missing values). Para tratarlos, tienes varias opciones:
  - Ignorar la tupla
  - Rellenar manualmente los datos (buena suerte con eso)
  - Utilizar una constante global para todos. No sirve de mucho
  - Rellenar utilizando la media o mediana
  - Rellenar con el valor m치s probable. Para eso, hace falta inferirlo, lo cual requiere alg칰n modelo. Es la mejor opci칩n. Entre algunos de los m칠todos que se utilizan, est치n
    - KNN (KNNI)
    - KNN con pesos (WKNNI)
    - Basada en clustering (KMI)
    - Basada en SVM (SVMI)
    - Event covering (EC), singular value descomposition (SVDI), local least squares imputation (LLSI)
- **Ruido**: datos que podr칤an no tener sentido ninguno. Muy dependientes del problema.
  - Tipos:
    - Class noise:
      - Ejemplos contradictorios
      - Mal etiquetados
    - Attribute noise:
      - Valores err칩neos
      - Missing values
      - Valores que te dan igual (don't care)
  - Tambi칠n se pueden considerar los **ejemplos borderline** (l칤mite) a aquellos que podr칤an ser o no ruidos, y los **ruidosos** (noisy) a los que seguro lo son
  - T칠cnicas para eliminarlos o suavizarlos:
    - **Ensemble filter** (EF):
      - Para cada algoritmo del aprendizaje, se utiliza una validaci칩n cruzada k-fold para etiquetar cada ejemplo como correcto o mal etiquetado.
      - Se usa un esquema de votaci칩n para determinar el conjunto final de ejemplos ruidosos:
        - Votaci칩n por consenso: ejemplo mal clasificado por todos
        - Votaci칩n por mayor칤a
    - **Cross validated committees filter** (CVCF). Similar a EF, pero con dos ideas principales:
      - El mismo algoritmo de aprendizaje (C4.5) se utiliza para crear clasificadores en varios subconjuntos de entrenamiento. Es especialmente importante utilizar 치rboles de decisi칩n, porque funcionan bien como filtro para el ruido.
      - Cada clasificador construido con la validaci칩n cruzada k-fold se utiliza para etiquetar todos los ejemplos de entrenamiento (no solo el de validaci칩n) como correctos o mal etiquetado.
    - **Iterative partitioning filter** (IPF):
      - Elimina los datos ruidosos en m칰ltiples iteraciones de CVCF. Para cuando se alcanza un cierto criterio. Generalmente, cuando el porcentaje de ejemplos ruidos est치 por debajo de un umbral.
- Detecci칩n de **datos an칩malos**:
  - Valor err칩neo != an칩malo (outlier).
  - Outliers: valores correctos, pero estad칤sticamente raros.
    - Son un problema para los algoritmos que aplican pesos.
    - T칠cnicas de detecci칩n:
      - Fijar una distancia y ver los que est치n a tomar por saco.
      - Clustering parcial: mirar qui칠n se queda fuera de los clusters al intentar agrupar los ejemplos.
    - 쯏 qu칠 hacemos con ellos?
      - Ignorarlos
      - Filtrar o reemplazar la columna. Un poco extremo
      - Filtrar o reemplazar la fila. Podr칤a sesgar el modelo. Cuidadito.
      - Reemplazar el valor por un nulo. No est치 mal si el algoritmo trabaja bien con missing values
      - Discretizar: los valores discretos no se ven tan afectados por las anomal칤as, al tratarse de categor칤as.
  - Se pueden eliminar los datos err칩neos mediante t칠cnicas de suavizado:
    - **Binning**: se consultan los vecinos. Los valores se distribuyen en cajas o intervalos (bins). Tiene un par de variantes:
      - Binning uniforme en intervalos (equiwidth)
      - Bininng uniforme en el contenido (equidepth):
        - Suavizar por la media o mediana
        - Suavizar por las fronteras
    - **Regresi칩n**: aplicar t칠cnicas de regresi칩n

### Reducci칩n de datos

- Seleccionar datos relevantes para facilitar la miner칤a. Vamos a ver ahora qu칠 se puede hacer:
- **Selecci칩n de caracter칤sticas** (feature selection):
  - Encontrar un subconjunto de variables que optimice la probabilidad de clasificar.
    - M치s atributos $\nRightarrow$ m치s 칠xito en la clasificaci칩n
    - Reducir la dimensi칩n del problema reduce la complejidad y el tiempo de ejecuci칩n
    - Con menos variables, la capacidad de generalizar aumenta
    - Los valores para ciertos atributos pueden ser costosos de obtener
    - Resultados m치s simples hacen que sea m치s f치cil entender el modelo
  - Es un problema de b칰squeda (del subconjunto de atributos 칩ptimo)
    - Los algoritmos tienen una estrategia de b칰squeda y una funci칩n objetivo que eval칰a el subconjunto.
    - $2^\text{n칰mero de atributos}$ resultados posibles.
    - Funciones objetivo:
      - **Envolventes** (wrappers): consiste en aplicar la t칠cnica de aprendizaje que hemos escogido y ver c칩mo rinden.
      - **Filtros** (filters): eval칰a los subconjuntos bas치ndose en la informaci칩n que contienen. Medidas filtro:
        - Medidas de separabilidad: usan distancia entre las clases
        - Correlaciones
        - Basadas en teor칤a de la informaci칩n. Dif칤ciles de calcular; se suelen usar heur칤sticas
        - Medidas de consistencia: intentan encontrar el n칰mero m칤nimo de caracter칤sticas que puedan separar las clases de la misma forma que lo hace el conjunto completo de variables.
  - **Ventajas**:
    - Envolventes:
      - Exactitud: m치s exactos que los de filtro
      - Capacidad para generalizar: poseen capacidad para evitar el sobreajuste debido a las t칠cnicas de validaci칩n cruzada
    - Filtro:
      - R치pidos. Suelen limitarse a c치lculos de frecuencias
      - Generalidad: al evaluar propiedades intr칤nsecas de los datos y no su interacci칩n con el clasificador, te vale para cualquiera.
  - **Desventajas**:
    - Envolventes:
      - Muy costosos: para cada evaluaci칩n hay que aprender un modelo y validarlo. A ver qu칠 algoritmo usas fiera.
      - P칠rdida de generalidad: la soluci칩n est치 sesgada por el clasificador que uses.
    - Filtros:
      - Tendencia a meter muchas variables.
  - Seg칰n la salida del algoritmo, se identifican algunos tipos:
    - Algoritmos **subconjunto de atributos**: devuelven un subconjunto optimizado seg칰n alg칰n criterio de evaluaci칩n
    - Algoritmos de **ranking**: devuelven una llista de atributos ordenados seg칰n alg칰n criterio de evaluaci칩n.
  - Esto no s칠 exactamente d칩nde va (porque los apuntes se entienden regular nada m치s):
    - **Selecci칩n hacia delante**: empiezas con el vac칤o, y empiezas a meter atributos.
      - Funciona mejor cuando hay el 칩ptimo tiene pocas variables
      - Incapaz de eliminar
    - **Selecci칩n hacia atr치s**: empiezas con el total, y te l칤as a quitar atributos.
      - Funciona mejor cuando el 칩ptimo tiene muchas variables
      - Tienes que reevaluar la utilidad de algunos atributos previamente descartados
    - **Selecci칩n l-m치s r-menos**: generalizaci칩n de forward y backward (Palante patr치s)
    - **Selecci칩n bidireccional**: implementaci칩n paralela de foward y backward. Hay que asegurar que los atributos eliminados por uno no son metidos por el otro.
    - **Selecci칩n flotante**: extensi칩n de l-m치s y r-menos que evita fijar l, r a priori. Hay dos m칠todos: uno comienza por el vac칤o, y otro por el total.
  - Tipos de algoritmos:
    - **Exhaustivos**: garantizan el 칩ptimo, pero el n칰mero de evaluaciones se te va de las manos (exponencial)
      - Branch and bound, beam search
    - **Heur칤sticos**: a침aden o eliminan variables al subconjunto candidato de forma secuencial. Se quedan pillados en 칩ptimos locales
      - Selecci칩n hacia delante, selecci칩n hacia atr치s, selecci칩n l-m치s r-menos, b칰squeda bidireccional, selecci칩n secuencial flotante
    - **Estoc치sticos**: usan aleatoriedad para salir de 칩ptimos locales:
      - Ascensi칩n de colinas con reinicios, enfriamiento estoc치stico, algoritmos gen칠ticos, enfriamiento simulado
      - Est치n de SPM socio.
- **Selecci칩n de instancias**:
  - Elige ejemplos que sean relevantes. Descarta la basurilla. Menos datos, m치s exactitud (=> generaliza mejor) y modelos m치s simples. La misma pesca, vamos
  - Tipos:
    - **Muestreo** (con y sin reposici칩n)
    - **Selecci칩n de prototipos o aprendizaje basado en instancias**:
      - Direcci칩n de b칰squeda: incremental, decremental, por lotes, mezclada y fija
      - Tipo de selecci칩n: condensaci칩n, edici칩n, h칤brido
      - Tipo de evaluaci칩n: filtrada o envolvente
    - **Aprendizaje activo**
  - Otra cosa que no s칠 realmente d칩nde va porque esto es un desastre. Algoritmos de selecci칩n de instancias creo:
    - **Condensed nearest neighbour** (CNN). Algoritmo cl치sico de condensaci칩n:
      - Incremental
      - Inserta solo las instancias mal clasificadas a partir de una selecci칩n aleatoria de una instancia de cada clase
      - Dependiente del orden de presentaci칩n
      - Tiende a retener puntos pertenecientes al borde
    - **Edited Nearest Neighbour** (ENN):
      - Por lotes
      - Se eliminan aquellas instancias que se clasifican err칩neamente usando sus k vecinos m치s cercanos
      - Suaviza fronteras, pero retiene el resto de puntos (muchos redundantes)
    - **AIIKNN**: ENN iterativo con k = 3, 5, 7
  - Eficiencia: el orden de los algoritmos es superior a $O(n^2)$. Suele rondar $O(n^3)$.
  - Los principales problemas a afrontar son: eficiencia, recursos, generalizaci칩n, representaci칩n.
  - Para grandes bases de datos, puedes usar estrategias de estratificaci칩n con los algoritmos de selecci칩n de instancias.
  - **Conjuntos de datos no balanceados**: algunos datasets tienen problemas con el recuento de las clases. Por ejemplo, que una clase tenga el 99% de las instancias, y otra el 1%.
  - Para procesarlas:
    - T칠cnicas de reducci칩n para balancear las clases, reduciendo las mayoritarias
    - Realizar oversampling (a침adir instancias de las clases menos representativas).
      - Un m칠todo bueno es **SMOTE**.
- **Discretizaci칩n**:
  - Caracter칤sticas:
    - Muy 칰tiles.
    - Representan informaci칩n m치s concisa, son f치ciles de entender, m치s cercanos a la representaci칩n del conocimiento
    - Puede hacerse antes de la obtenci칩n de conocimiento o durante esa misma etapa.
    - Algunos algoritmos solo admiten valores discretos.
  - Dependiente de las necesidades:
    - **Supervisados vs no supervisados**: consideran o no el atributo objetivo
      - No supervisados:
        - Discretizaci칩n de igual amplitud. Pueden producir desequilibrios
        - Igual frecuencia
          - Evita desequilibrios, y te da puntos de corte m치s intuitivos
          - Pero cuidado. Deber칤as crear cajas para valores especiales.
        - Clustering
      - Supervisados:
        - Basados en entrop칤a
          - Entropy MDLP; minimum description length principle. Encontrar el coste de comunicaci칩n entre un emisor y un receptor. Una partici칩n inducida por un punto de corte es aceptada si y solo si el coste del mensaje requerido para enviar antes de particionar es mayor que el requerido despu칠s de particionar
        - M칠todos chi cuadrado
    - **Din치micos vs est치ticos**: mientras se construye el modelo
    - **Locales vs globales**: centrados en una subregi칩n o considerando todo el espacio
    - **Top down vs bottom up**: empiezan con una lista vac칤a o llena de puntos de corte
    - **Directos vs incrementales**: usan o no un proceso de optimizaci칩n posterior
  - Y cu치l de todas las formas es mejor?
    - [a](https://twitter.com/misterjagger_/status/1397647916722962437)
    - Puedes evaluarlo teniendo en cuenta el n칰mero de intervalos, n칰mero de inconsistencias causadas, tasa de acierto predictivo, tama침o del modelo generado...


## Tema 6: Clustering

Se enmarca en el contexto del aprendizaje no supervisado con variables que toman valores continuos.

El clustering se puede ver como una tarea de preprocesado antes de aplicar alguna t칠cnica de descubrimiento de conocimiento o como una t칠cnica de descubrimiento del conocimiento en s칤 para obtener informaci칩n sobre la distribuci칩n de los datos.

* Medidas de distancia:
  * Un 칰nico atributo num칠rico $A$: $d(x,y)=A(X)-Y(X)$
  * Varios atributos num칠ricos: distancia eucl칤dea.
  * Atributos nominales: 1 si los valores son diferentes y 0 si son el mismo.
* Las medidas son sensibles al rango de valores que toman las variables $\Rightarrow$ hay que **normalizar**.

### K-Means

Necesita como argumento el n칰mero de clusters. Pilla k centroides aleatorios y asigna cada punto al centroide m치s cercano, recalcula el centro del cluster y vuelve a asignar los puntos al centroide m치s cercano. As칤 sucesivamente hasta que no haya cambios en los clusters.

* Eficiente: $O(tkn)$ donde $t\equiv\text{ numero de iteraciones }, n\equiv\text{ numero de objetos }, k\equiv\text{ numero de clusters }$.
* Puede finalizar en un 칩ptimo local, lo cual se puede solucionar reinicializando la semilla aleatoria o usando t칠cnicas de b칰squeda m치s potentes.
* S칩lo fufa cuando el concepto de medida es definible.
* Hay que fijar el n칰mero de clusters.
  * Iterar distintos valores y elegir la mejor soluci칩n.
* D칠bil ante ruido y outliers.
* S칩lo genera clusters convexos.

### Mean Shift

Fija un radio (*bandwidth*) y va desplazando centroides a regiones m치s densas. El radio se puede estimar por KNN. Los clusters que genera son convexos

### DBSCAN

* Acepta como par치metros un radio `eps` y el tama침o m칤nimo `minPts`.
* A partir de un punto busca otros puntos que pillen dentro del radio y si hay m치s de `minPts` lo a침ade al cluster, as칤 hasta que no se alcancen m치s puntos. Los puntos que no entran en ning칰n cluster los etiqueta como ruido.
* `eps` se puede estimar con k-distancia.
* Puede encontrar cluster con distintas formas y es robusto a outliers.
* En las pr치cticas no vale pa na.

### BIRCH

Agrupa conforme se reciben objetos (clustering incremental). $CF=\{N, LS, SS\}$:

* $N$ Number of objects.
* $LS$: Linear Sum.
* $SS$: Squared Sum.

Cuando llega un objeto va descendiendo por el 치rbol escogiendo el CF m치s cercano en cada nodo, y al llegar a una hoja si se puede meter en un CF se mete y si no se crea un CF nuevo si hay menos de $L$. En caso de haber $L$ se divide la hoja en dos tomando los dos CF m치s lejanos de la hoja anterior.

### Medidas

* **Silhouette**: Mide c칩mo de similares son los objetos de un cluster en comparaci칩n con los de otros. Se calculan coeficientes $s(i)$ por cada objeto, mejor cuanto m치s cercano a 1, si se acerca a 0 significa que est치 en la frontera de dos clusters. La media de todos los $s(i)$ es el coeficiente *silhouette*.
* **Calinski-Harabasz**: Raz칩n entre la dispersi칩n intra-clusters y la dispersi칩n interclusters. Cuanto mayor sea el valor de este coeficiente, mejor.

### M칠todos aglomerativos

En cada paso se fusionan los clusters m치s cercanos.

* **Enlace simple:** Se minimiza la distancia m칤nima entre elementos de cada grupo.
* **Enlace completo:** Se minimiza la distancia m치xima entre elementos de cada grupo.
* **Varianza m칤nima (Ward):** Fusiona el par de clusters que genera un agrupamiento con m칤nima varianza.
* **Distancia entre centroides.**

### M칠todos divisivos

Partiendo de un s칩lo cluster, se subdivide hasta que se alcanza un criterio de parada o cada cluter contiene un solo objeto. Variantes:

* **Unidimensional**: Partici칩n en base a una variable.
* **Multidimensional**: Se consideran todas las variables.

## Tema 7: Patrones frecuentes y reglas de asociaci칩n

Se enmarca en el contexto del aprendizaje no supervisado con variables discretas. Idea:

```
Antecedente => Consecuente [soporte, confianza]
```

### Algoritmo APRIORI

* No hay que fijar atributos, se generan de forma autom치tica
* Variedades para tratar todo tipo de datos
* Especificar m칤nimo soporte y m치ximo n칰mero de reglas.
* **Principio a priori**: Cualquier subconjunto de un conjunto frecuente es frecuente.
* **Principio de poda en Apriori:** Si un conjunto no es frecuente, no hay necesidad de generar sus superconjuntos.

Par치metros **soporte** y **confianza**:

* Si el soporte m칤nimo **s** es alto habr치 pocas reglas que ocurren con frecuencia, si es bajo habr치 muchas reglas que ocurren raramente.
* Si la confianza m칤nima **c** es alta habr치 pocas reglas 'casi ciertas l칩gicamente' y si es baja habr치 muchas reglas muy inciertas.
* Valores t칤picos: soporte entre 2-10% y confianza entre 70-90%.

### Medidas de inter칠s

* $soporte = P(antecedente\cap consecuente)$
* $confianza = \text{Probablilidad condicionada } = \frac{soporte}{P(antecedente)} = P(\text{consecuente} \vert \text{antecedente})$

El problema de la confianza es que se calcula en base 칰nicamente de los atributos que aparecen en la regla, no se tiene en cuenta el total de datos.

* Inter칠s, correlaci칩n, empuje, *lift*:
  $$
  lift(A\Rightarrow B) = \dfrac{P(B/A)}{P(B)}=\dfrac{P(A\cap B)}{P(A)P(B)}
  $$
  Si A y B son independientes entonces $P(A\cap B)=P(A)P(B)$ y $lift=1$.

  Si $lift>1$ A y B est치n positivamente correlacionados. Si $lift < 1$ entonces A y B est치n negativamente correlacionados.

## Tema 8: Deep Learning

Utilizar una red neuronal con varias capas de nodos entre entrada y salida. Estas capas hacen una identificaci칩n de caracter칤sticas y procesamiento en una serie de etapas. Para cada ejemplo de entrenamiento se propaga la entrada por la red para obtener una salida, que se compara con la salida esperada y se retropropaga el error para ir ajustando suavemente los pesos desde la 칰ltima hasta la primera capa.

### La nueva forma de entrenar RNA multicapa: aprendizaje profundo

Las capas sin salida se entrenan para ser un codificador autom치tico (auto-encoder), aprendiendo buenas caracter칤sticas que describen lo que viene de la capa anterior. Un auto-encoder est치 entrenado con un algoritmo de ajuste de peso para reproducir la entrada. Como hay menos unidades que entradas, est치n obligadas a convertirse en buenos detectores de caracter칤sticas.

Las t칠cnicas tradicionales utilizaban un simple detector de caracter칤sticas antes de utilizar un clasificador. En deep learning se usa una serie de capas ('layers'): input layer, hidden layers y output layers.

### CNN: Convolucional Neural Network

No existe forma humana de explicar esto peor de lo que est치 en las diapositivas as칤 que utiliza la [p치gina esta](https://towardsdatascience.com/applied-deep-learning-part-4-convolutional-neural-networks-584bc134c1e2).

Problema: Necesita una gran cantidad de datos. Soluci칩n: preprocesado o 'data augmentation', que consiste en replicar instancias del conjunto de entrenamiento con alguna transformaci칩n como traslaciones, rotaciones, simetr칤as... Esto favorece la robustez del modelo.

## Tema 9: Problemas regulares

Clases desbalanceadas: Supone un problema a la hora de la correcta identificaci칩n de los conceptos a aprender. Las caracter칤sticas intr칤nsecas de los datos son fuente de diversos problemas, como el solapamiento o los valores perdidos. La clase mayoritaria solapa la minoritaria, dejando fronteras ambiguas.

El uso de m칠tricas como la precisi칩n (accuracy) conduce a conclusiones err칩neas, se sobreajusta la clase mayoritaria.

|         | Predicci칩n + | Predicci칩n - |
| ------- | ------------ | ------------ |
| Class + | TP           | FN           |
| Class - | FP           | TN           |

* Positive True Ratio: TPR (sensitivity) $a^+=\frac{TP}{TP+FN}$ Los que aciertas de la clase positiva.
* Negative True Ratio: TNR (specificity) $a^-=\frac{TN}{TN+FP}$ Los que aciertas de la clase negativa.
* True ratio (G-mean): Media geom칠trica de $a^+$ y $a^-$: $GM=\sqrt{a^+\cdot a^-}$
* F1-score es la media arm칩nica de precisi칩n y recall:
  * Precisi칩n: $PPV=\frac{TP}{TP+FP}$
  * Recall: sensitivity (TPR)
  * $F_1 = 2 \dfrac{precision\cdot recall}{precision+recall}$
* F-Measure en general: $F_\beta=(1+\beta^2)\dfrac{precision\cdot recall}{\beta^2\cdot precision+recall}$
* $AUC=\dfrac{1+TPR-FPR}2$









## 9. Problemas singulares

- **Resampling**:
  - **CNN**: Selecciona aleatoriamente los ejemplos de la clase mayoritaria que no pueden clasificarse correctamente.
  - **Tomek links**: quitar ejemplos borderline y ruido de la clase mayoritaria.
- **Oversampling**:
  - **Random oversampling**: tiene el efecto de hacer que la regi칩n de decisi칩n de la clase minoritaria sea muy espec칤fica. En un 치rbol de decisi칩n, produce overfitting.
  - **SMOTE**: generaliza la regi칩n de decisi칩n de la clase minoritaria. Presta atenci칩n a los ejemplos de la clase, sin producir overfitting. Cuidado, que act칰a un poco a lo loco.
    - SMOTE + Tomek: *Instead of removing only the majority class examples that form Tomek links, examples from both classes are removed*.
    - SMOTE + ENN: removes any example whose class label differs from the class of at least two of their neighbors. Quita m치s que con Tomek. Quita de ambas clases.